Urban Sound Classification: Custom MLP vs. PyTorch CNN

This project is a comprehensive deep learning study developed to classify urban sounds using the Urban Sound Dataset. The primary goal is to analyze different audio feature extraction methods (Mel Spectrogram vs. MFCC) and to compare a from-scratch neural network with a modern CNN architecture implemented in PyTorch.

Project Features

Key technical aspects that make this project unique:
	â€¢	MLP from Scratch with NumPy:
A Multi-Layer Perceptron engine is implemented using only mathematical formulations (Gradient Descent, Backpropagation, ReLU, Softmax) without relying on sklearn or torch.
	â€¢	Dynamic CNN with PyTorch:
A flexible Convolutional Neural Network (CNN) is built to process audio spectrograms using a dynamic layer structure.
	â€¢	Audio Feature Analysis:
Raw audio signals are processed to extract both Mel Spectrogram and MFCC representations, and their impact on classification performance is evaluated.

ðŸ“‚ File Structure
	â€¢	main.py: Main execution script. Loads data, trains MLP and CNN models, compares results, and saves the best-performing models.
	â€¢	data_loader.py: Reads audio files (WAV), performs Mel Spectrogram and MFCC transformations using librosa, and prepares the dataset (Folds 1â€“8 for training, Folds 9â€“10 for testing).
	â€¢	mlp_model.py: From-scratch implementation. NumPy-based class containing the mathematical backbone of the neural network (forward and backward passes).
	â€¢	cnn_model.py: CNN architecture built using PyTorch nn.Module, including Conv2D and pooling layers.

Methodology

1. Data Preprocessing
	â€¢	Audio files are loaded using librosa.
	â€¢	Mel Spectrogram: Visualizes the temporal evolution of frequency components (processed as 2D images for CNNs).
	â€¢	MFCC: Extracts features that are closer to human auditory perception.
	â€¢	Data is normalized using methods such as Standard Scaling or Min-Max Scaling.

2. Models

A. Custom MLP (NumPy)
	â€¢	Activation Functions: ReLU (hidden layers), Softmax (output layer).
	â€¢	Optimization: Stochastic Gradient Descent (SGD).
	â€¢	Architecture: Flexible layer sizes (e.g., [Input, 512, 256, 10]).

B. CNN (PyTorch)
	â€¢	Architecture: Two or more convolutional blocks followed by fully connected layers.
	â€¢	Training: CrossEntropyLoss with the Adam optimizer.
	â€¢	Feature Support: Dynamic structure supporting both Mel Spectrogram (128Ã—128) and MFCC (40Ã—128) inputs.

Results

Key findings from the experiments:
	â€¢	CNNs outperform MLPs by effectively capturing spatial patterns in spectrograms.
	â€¢	Mel Spectrograms generally yield better performance than MFCCs in deep learning models due to their richer representation of audio texture.
